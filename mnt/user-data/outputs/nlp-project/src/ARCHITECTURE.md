# System Architecture

## ğŸ“ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA SOURCES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CSV Files  â”‚  JSON Files  â”‚  PostgreSQL  â”‚  MySQL  â”‚  Python   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚              â”‚            â”‚          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DataLoader    â”‚
                    â”‚   (Handler)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Pipeline     â”‚
                    â”‚  (Orchestrator) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Sentiment     â”‚
                    â”‚    Analyzer     â”‚
                    â”‚  (NLTK/TextBlob)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DataSaver     â”‚
                    â”‚   (Handler)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚             â”‚              â”‚                â”‚
       â–¼             â–¼              â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV    â”‚  â”‚   JSON   â”‚  â”‚  Database   â”‚  â”‚ Summary  â”‚
â”‚  Output  â”‚  â”‚  Output  â”‚  â”‚   Tables    â”‚  â”‚  Stats   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Component Details

### 1. Data Layer (data_handler.py)

#### DataLoader
- Loads data from multiple sources
- Validates column/field existence
- Handles errors gracefully
- Returns pandas DataFrame

**Supported Sources:**
- CSV files
- JSON files  
- PostgreSQL databases
- MySQL databases
- Python lists

#### DataSaver
- Saves processed data to multiple destinations
- Generates summary statistics
- Creates output directories automatically

**Supported Outputs:**
- CSV files
- JSON files
- Database tables
- Summary text files

### 2. Processing Layer (sentiment_analyzer.py)

#### SentimentAnalyzer
- Text preprocessing (cleaning, normalization)
- Sentiment scoring using TextBlob
- Batch processing support

**Features:**
- Polarity: -1 (negative) to +1 (positive)
- Subjectivity: 0 (objective) to 1 (subjective)
- Label classification: positive/negative/neutral

### 3. Orchestration Layer (pipeline.py)

#### SentimentPipeline
- Coordinates data flow
- Manages end-to-end processing
- Logging and error handling
- Progress tracking

**Pipeline Types:**
- CSV â†’ Processing â†’ CSV
- JSON â†’ Processing â†’ JSON
- Database â†’ Processing â†’ Database
- Custom DataFrame â†’ Processing â†’ Any output

### 4. Interface Layer (run_pipeline.py)

#### CLI Interface
- Command-line argument parsing
- Configuration management
- User-friendly error messages

## ğŸ”„ Data Flow

### CSV Processing Flow
```
1. User executes: run_pipeline.py --source-type csv ...
2. CLI parses arguments
3. Pipeline initialized
4. DataLoader reads CSV â†’ pandas DataFrame
5. Pipeline adds timestamp column
6. For each row:
   - Extract text from specified column
   - Preprocess text (clean, normalize)
   - Analyze sentiment (polarity, subjectivity)
   - Classify label (positive/negative/neutral)
7. Append results to DataFrame
8. DataSaver writes to CSV output
9. Optional: Generate summary statistics
10. Return processed DataFrame
```

### Database Processing Flow
```
1. User executes: run_pipeline.py --source-type postgres ...
2. DataLoader connects to source database
3. Execute SQL query â†’ pandas DataFrame
4. Process data (same as above)
5. DataSaver connects to destination database
6. Write results to table (append/replace/fail)
7. Close connections
```

## ğŸ³ Docker Architecture

### Container Structure
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     nlp-sentiment-app Container        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Python 3.9                      â”‚  â”‚
â”‚  â”‚  + NLTK, TextBlob, pandas        â”‚  â”‚
â”‚  â”‚  + SQLAlchemy, psycopg2          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Application Code                â”‚  â”‚
â”‚  â”‚  - src/                          â”‚  â”‚
â”‚  â”‚  - data/                         â”‚  â”‚
â”‚  â”‚  - run_pipeline.py               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Network: nlp-network
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     postgres Container                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PostgreSQL 15                   â”‚  â”‚
â”‚  â”‚  Database: nlpdb                 â”‚  â”‚
â”‚  â”‚  Tables: reviews, sentiment_resultsâ”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Persistent Volume                â”‚  â”‚
â”‚  â”‚  postgres_data                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ CI/CD Pipeline (CircleCI)

### Workflow
```
GitHub Push
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Checkout Code   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Install Python   â”‚
â”‚  Dependencies     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Download NLTK    â”‚
â”‚  Data             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Run Tests       â”‚
â”‚   with Coverage   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Store Test       â”‚
â”‚  Results          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Build Docker     â”‚
â”‚  Image            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Test Docker      â”‚
â”‚  Image            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Success! âœ“
```

## ğŸ” Security Considerations

1. **Environment Variables**: Use `.env` files for credentials
2. **SQL Injection**: Use parameterized queries (SQLAlchemy handles this)
3. **File Permissions**: Validate paths, use safe file operations
4. **Database Connections**: Always use connection pooling, dispose properly
5. **Input Validation**: Verify column/field existence before processing

## ğŸ“ˆ Scalability

### Current Limits
- Single-threaded processing
- In-memory DataFrame operations
- Best for < 1M records

### Future Scaling Options
1. **Batch Processing**: Process in chunks
2. **Parallel Processing**: Use multiprocessing/threading
3. **Distributed Processing**: Apache Spark, Dask
4. **Async I/O**: asyncio for database operations
5. **Message Queues**: RabbitMQ/Kafka for pipeline stages

## ğŸ§ª Testing Strategy

```
Unit Tests (pytest)
    â”œâ”€â”€ test_sentiment_analyzer.py
    â”‚   â”œâ”€â”€ Positive sentiment detection
    â”‚   â”œâ”€â”€ Negative sentiment detection
    â”‚   â”œâ”€â”€ Neutral sentiment detection
    â”‚   â”œâ”€â”€ Text preprocessing
    â”‚   â””â”€â”€ Batch processing
    â”‚
    â”œâ”€â”€ test_data_handler.py
    â”‚   â”œâ”€â”€ CSV loading
    â”‚   â”œâ”€â”€ JSON loading
    â”‚   â”œâ”€â”€ Data saving
    â”‚   â””â”€â”€ Error handling
    â”‚
    â””â”€â”€ test_pipeline.py
        â”œâ”€â”€ End-to-end CSV pipeline
        â”œâ”€â”€ Custom DataFrame pipeline
        â””â”€â”€ Empty text handling

Integration Tests (CircleCI)
    â”œâ”€â”€ Full pipeline execution
    â”œâ”€â”€ Docker image building
    â””â”€â”€ Docker container testing
```

## ğŸ” Monitoring & Logging

```python
Logging Levels:
    INFO  â†’ Pipeline progress, records processed
    WARNING â†’ Empty texts, missing data
    ERROR â†’ File not found, connection failures
    
Example Log Output:
    2024-01-15 10:30:00 - pipeline - INFO - Pipeline initialized
    2024-01-15 10:30:01 - pipeline - INFO - âœ“ Loaded 10 rows from CSV
    2024-01-15 10:30:02 - pipeline - INFO - Processing 10 texts...
    2024-01-15 10:30:03 - pipeline - INFO - Processed 10/10 rows
    2024-01-15 10:30:04 - pipeline - INFO - âœ“ Saved 10 rows to CSV
```

## ğŸ’¾ Database Schema

```sql
-- Source Data
reviews
    â”œâ”€â”€ id (SERIAL PRIMARY KEY)
    â”œâ”€â”€ review_text (TEXT)
    â”œâ”€â”€ rating (INTEGER)
    â”œâ”€â”€ product_id (VARCHAR)
    â”œâ”€â”€ user_id (VARCHAR)
    â””â”€â”€ created_at (TIMESTAMP)

-- Processed Results
sentiment_results
    â”œâ”€â”€ id (SERIAL PRIMARY KEY)
    â”œâ”€â”€ review_id (INTEGER FK â†’ reviews.id)
    â”œâ”€â”€ review_text (TEXT)
    â”œâ”€â”€ sentiment (VARCHAR: positive/negative/neutral)
    â”œâ”€â”€ polarity (FLOAT: -1 to 1)
    â”œâ”€â”€ subjectivity (FLOAT: 0 to 1)
    â””â”€â”€ processed_at (TIMESTAMP)

Indexes:
    - reviews(product_id)
    - reviews(created_at)
    - sentiment_results(sentiment)
    - sentiment_results(processed_at)
```
