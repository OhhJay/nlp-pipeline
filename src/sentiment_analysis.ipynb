{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Sentiment Analysis NLP Project\n",
    "## Interactive Colab Notebook\n",
    "\n",
    "This notebook demonstrates sentiment analysis using our custom analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install nltk textblob -q\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## 2. Clone Repository (Optional)\n",
    "\n",
    "If you want to use the code from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "git-clone"
   },
   "outputs": [],
   "source": [
    "# Uncomment to clone from GitHub\n",
    "# !git clone https://github.com/yourusername/nlp-project.git\n",
    "# import sys\n",
    "# sys.path.append('/content/nlp-project/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code"
   },
   "source": [
    "## 3. Import Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-analyzer"
   },
   "outputs": [],
   "source": [
    "# For this demo, we'll define the analyzer inline\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from typing import Dict, List\n",
    "import re\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the sentiment analyzer\"\"\"\n",
    "        try:\n",
    "            nltk.data.find('tokenizers/punkt')\n",
    "        except LookupError:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def analyze_sentiment(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Analyze sentiment of text\"\"\"\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        blob = TextBlob(cleaned_text)\n",
    "        \n",
    "        return {\n",
    "            'polarity': blob.sentiment.polarity,\n",
    "            'subjectivity': blob.sentiment.subjectivity,\n",
    "            'label': self._get_sentiment_label(blob.sentiment.polarity)\n",
    "        }\n",
    "    \n",
    "    def _get_sentiment_label(self, polarity: float) -> str:\n",
    "        \"\"\"Convert polarity score to label\"\"\"\n",
    "        if polarity > 0.1:\n",
    "            return 'positive'\n",
    "        elif polarity < -0.1:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    def batch_analyze(self, texts: List[str]) -> List[Dict[str, float]]:\n",
    "        \"\"\"Analyze sentiment for multiple texts\"\"\"\n",
    "        return [self.analyze_sentiment(text) for text in texts]\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = SentimentAnalyzer()\n",
    "print(\"âœ“ Sentiment Analyzer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examples"
   },
   "source": [
    "## 4. Basic Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-examples"
   },
   "outputs": [],
   "source": [
    "# Test with sample texts\n",
    "sample_texts = [\n",
    "    \"I absolutely love this product! It's amazing!\",\n",
    "    \"This is terrible and disappointing.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"The customer service was excellent and very helpful!\",\n",
    "    \"Worst experience ever. Never coming back.\"\n",
    "]\n",
    "\n",
    "print(\"Sentiment Analysis Results:\\n\" + \"=\"*60)\n",
    "for text in sample_texts:\n",
    "    result = analyzer.analyze_sentiment(text)\n",
    "    print(f\"\\nðŸ“ Text: {text}\")\n",
    "    print(f\"   Sentiment: {result['label'].upper()}\")\n",
    "    print(f\"   Polarity: {result['polarity']:.3f}\")\n",
    "    print(f\"   Subjectivity: {result['subjectivity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive"
   },
   "source": [
    "## 5. Interactive Analysis\n",
    "\n",
    "Try your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "user-input"
   },
   "outputs": [],
   "source": [
    "# Analyze your own text\n",
    "user_text = input(\"Enter text to analyze: \")\n",
    "result = analyzer.analyze_sentiment(user_text)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Sentiment: {result['label'].upper()}\")\n",
    "print(f\"Polarity Score: {result['polarity']:.3f} (range: -1 to 1)\")\n",
    "print(f\"Subjectivity Score: {result['subjectivity']:.3f} (range: 0 to 1)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Analyze multiple texts and visualize\n",
    "texts = [\n",
    "    \"Excellent product!\",\n",
    "    \"Pretty good overall\",\n",
    "    \"It's just okay\",\n",
    "    \"Not great\",\n",
    "    \"Terrible quality\"\n",
    "]\n",
    "\n",
    "results = analyzer.batch_analyze(texts)\n",
    "polarities = [r['polarity'] for r in results]\n",
    "subjectivities = [r['subjectivity'] for r in results]\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Polarity chart\n",
    "colors = ['green' if p > 0.1 else 'red' if p < -0.1 else 'gray' for p in polarities]\n",
    "ax1.barh(range(len(texts)), polarities, color=colors, alpha=0.7)\n",
    "ax1.set_yticks(range(len(texts)))\n",
    "ax1.set_yticklabels([t[:30] + '...' if len(t) > 30 else t for t in texts])\n",
    "ax1.set_xlabel('Polarity Score')\n",
    "ax1.set_title('Sentiment Polarity Analysis')\n",
    "ax1.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "ax2.scatter(polarities, subjectivities, c=colors, s=100, alpha=0.6)\n",
    "ax2.set_xlabel('Polarity')\n",
    "ax2.set_ylabel('Subjectivity')\n",
    "ax2.set_title('Polarity vs Subjectivity')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch"
   },
   "source": [
    "## 7. Batch Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-process"
   },
   "outputs": [],
   "source": [
    "# Simulate processing multiple reviews\n",
    "reviews = [\n",
    "    \"Amazing quality and fast shipping!\",\n",
    "    \"Product arrived damaged.\",\n",
    "    \"Good value for money.\",\n",
    "    \"Not as described, very disappointed.\",\n",
    "    \"Exceeded my expectations!\",\n",
    "    \"Average product, nothing special.\",\n",
    "    \"Great customer support!\",\n",
    "    \"Poor quality materials.\"\n",
    "]\n",
    "\n",
    "results = analyzer.batch_analyze(reviews)\n",
    "\n",
    "# Summary statistics\n",
    "positive_count = sum(1 for r in results if r['label'] == 'positive')\n",
    "negative_count = sum(1 for r in results if r['label'] == 'negative')\n",
    "neutral_count = sum(1 for r in results if r['label'] == 'neutral')\n",
    "\n",
    "print(\"\\nðŸ“Š Batch Analysis Summary:\")\n",
    "print(f\"Total reviews: {len(reviews)}\")\n",
    "print(f\"Positive: {positive_count} ({positive_count/len(reviews)*100:.1f}%)\")\n",
    "print(f\"Negative: {negative_count} ({negative_count/len(reviews)*100:.1f}%)\")\n",
    "print(f\"Neutral: {neutral_count} ({neutral_count/len(reviews)*100:.1f}%)\")\n",
    "print(f\"\\nAverage polarity: {np.mean([r['polarity'] for r in results]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-csv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame with results\n",
    "df = pd.DataFrame({\n",
    "    'text': reviews,\n",
    "    'sentiment': [r['label'] for r in results],\n",
    "    'polarity': [r['polarity'] for r in results],\n",
    "    'subjectivity': [r['subjectivity'] for r in results]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('sentiment_results.csv', index=False)\n",
    "print(\"\\nâœ“ Results saved to sentiment_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
